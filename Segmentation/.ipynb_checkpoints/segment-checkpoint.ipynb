{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3af87ca-ff17-4526-908b-95beb1a104ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T07:24:45.844532Z",
     "iopub.status.busy": "2022-12-03T07:24:45.844387Z",
     "iopub.status.idle": "2022-12-03T07:24:45.847391Z",
     "shell.execute_reply": "2022-12-03T07:24:45.847015Z",
     "shell.execute_reply.started": "2022-12-03T07:24:45.844497Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21f8d50-6939-44a7-a993-1b7ced3db2a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T06:53:15.008635Z",
     "iopub.status.busy": "2022-12-03T06:53:15.008378Z",
     "iopub.status.idle": "2022-12-03T06:53:15.010388Z",
     "shell.execute_reply": "2022-12-03T06:53:15.010016Z",
     "shell.execute_reply.started": "2022-12-03T06:53:15.008621Z"
    }
   },
   "source": [
    "### ENV\n",
    "#### Create basic env\n",
    "``` \n",
    "    mamba install pytorch=1.11 torchvision -y\n",
    "    mamba install -c conda-forge mmcv-full\n",
    "```\n",
    "#### Clone mmseg\n",
    "`git clone git@github.com:open-mmlab/mmsegmentation.git`\n",
    "\n",
    "#### Download dataset\n",
    "```\n",
    "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "tar -xvf VOCtrainval_11-May-2012.tar\n",
    "```\n",
    "you may also want this, these are the augmentations(?):\n",
    "```\n",
    "wget  http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz\n",
    "tar -xvf benchmark.tgz\n",
    "```\n",
    "### Run training:\n",
    "#### First, register your model\n",
    "insert your model in:\n",
    "\n",
    "`mmseg/models/backbones/__init__.py`\n",
    "#### Run training\n",
    "```\n",
    "cd /home/me.docker/work/finetune/Segmentation/mmsegmentation\n",
    "sh tools/dist_train.sh /home/jovyan/finetune/Segmentation/configs/linear_r50_512x512_40k_voc12aug.py 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3495594-69fd-4772-870c-4079987a36d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T07:24:45.853605Z",
     "iopub.status.busy": "2022-12-03T07:24:45.853442Z",
     "iopub.status.idle": "2022-12-03T07:24:47.153538Z",
     "shell.execute_reply": "2022-12-03T07:24:47.152903Z",
     "shell.execute_reply.started": "2022-12-03T07:24:45.853593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me.docker/.conda/envs/mmseg/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/me.docker/work/finetune/Segmentation')\n",
    "\n",
    "from voc import VOCSegmentation, get_transforms\n",
    "import mmseg\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c97da7d-b0ad-47cd-b7c2-3d42b7738221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T07:24:47.154725Z",
     "iopub.status.busy": "2022-12-03T07:24:47.154465Z",
     "iopub.status.idle": "2022-12-03T07:24:47.164077Z",
     "shell.execute_reply": "2022-12-03T07:24:47.163680Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.154707Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform, val_transform = get_transforms(256)    \n",
    "data_root = \"/home/jovyan/data/voc_seg/train_val\"\n",
    "batch_size = 8\n",
    "val_batch_size = 8\n",
    "\n",
    "train_dst = VOCSegmentation(root=data_root,\n",
    "                            image_set='train', download=False, transform=train_transform)\n",
    "val_dst = VOCSegmentation(root=data_root,\n",
    "                          image_set='val', download=False, transform=val_transform)\n",
    "\n",
    "train_loader = data.DataLoader(train_dst, batch_size=batch_size, \n",
    "                               shuffle=True, num_workers=2, drop_last=True) \n",
    "val_loader = data.DataLoader(val_dst, batch_size=val_batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9089762-0f6f-4256-86be-303ad0d241fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T07:24:47.165376Z",
     "iopub.status.busy": "2022-12-03T07:24:47.165035Z",
     "iopub.status.idle": "2022-12-03T07:24:47.576065Z",
     "shell.execute_reply": "2022-12-03T07:24:47.575614Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.165362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmseg.models.builder import HEADS\n",
    "from mmseg.models.decode_heads.decode_head import BaseDecodeHead\n",
    "\n",
    "\n",
    "@HEADS.register_module()\n",
    "class LinearHead(BaseDecodeHead):\n",
    "    \"\"\"Just a batchnorm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        assert self.in_channels == self.channels\n",
    "        self.bn = nn.SyncBatchNorm(self.in_channels)\n",
    "\n",
    "    def _forward_feature(self, inputs):\n",
    "        \"\"\"Forward function for feature maps before classifying each pixel with\n",
    "        ``self.cls_seg`` fc.\n",
    "        Args:\n",
    "            inputs (list[Tensor]): List of multi-level img features.\n",
    "        Returns:\n",
    "            feats (Tensor): A tensor of shape (batch_size, self.channels,\n",
    "                H, W) which is feature map for last layer of decoder head.\n",
    "        \"\"\"\n",
    "        # accept lists (for cls token)\n",
    "        input_list = []\n",
    "        for x in inputs:\n",
    "            if isinstance(x, list):\n",
    "                input_list.extend(x)\n",
    "            else:\n",
    "                input_list.append(x)\n",
    "        for i, x in enumerate(input_list):\n",
    "            if len(x.shape) == 2:\n",
    "                input_list[i] = x[:, :, None, None]\n",
    "        x = self._transform_inputs(input_list)\n",
    "        feats = self.bn(x)\n",
    "        return feats\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        output = self._forward_feature(inputs)\n",
    "        output = self.cls_seg(output)\n",
    "        return output\n",
    "# type=\"LinearHead\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90030b99-ecb3-4b12-9b85-824f9c0c536b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T07:24:47.577090Z",
     "iopub.status.busy": "2022-12-03T07:24:47.576714Z",
     "iopub.status.idle": "2022-12-03T07:24:47.580753Z",
     "shell.execute_reply": "2022-12-03T07:24:47.580407Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.577075Z"
    }
   },
   "outputs": [],
   "source": [
    "# vicregl config\n",
    "norm_cfg = dict(type=\"SyncBN\", requires_grad=True)\n",
    "model = dict(\n",
    "    type=\"EncoderDecoder\",\n",
    "    backbone=dict(\n",
    "        type=\"ResNet\",\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        dilations=(1, 1, 2, 4),\n",
    "        strides=(1, 2, 1, 1),\n",
    "        norm_cfg=norm_cfg,\n",
    "        norm_eval=False,\n",
    "        style=\"pytorch\",\n",
    "        contract_dilation=True,\n",
    "        frozen_stages=4,\n",
    "    ),\n",
    "    decode_head=dict(\n",
    "        type=\"LinearHead\",\n",
    "        in_channels=2048,\n",
    "        in_index=3,\n",
    "        channels=2048,\n",
    "        dropout_ratio=0.1,\n",
    "        num_classes=21,\n",
    "        norm_cfg=norm_cfg,\n",
    "        align_corners=False,\n",
    "        loss_decode=dict(type=\"CrossEntropyLoss\", use_sigmoid=False, loss_weight=1.0),\n",
    "    ),\n",
    "    test_cfg=dict(mode=\"whole\"),\n",
    "    init_cfg=dict(type=\"Pretrained\", checkpoint=\"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "587ccdda-e58d-4bb0-b155-e4a3176bb491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T07:24:47.581540Z",
     "iopub.status.busy": "2022-12-03T07:24:47.581267Z",
     "iopub.status.idle": "2022-12-03T07:24:47.583858Z",
     "shell.execute_reply": "2022-12-03T07:24:47.583524Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.581525Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_channels=2048\n",
    "in_index=3\n",
    "channels=2048\n",
    "dropout_ratio=0.1\n",
    "num_classes=21\n",
    "norm_cfg=dict(type=\"SyncBN\", requires_grad=True)\n",
    "align_corners=False\n",
    "loss_decode=dict(type=\"CrossEntropyLoss\", use_sigmoid=False, loss_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc153f97-c3b5-4a14-a025-1ce0cb927e12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-03T07:24:47.584598Z",
     "iopub.status.busy": "2022-12-03T07:24:47.584331Z",
     "iopub.status.idle": "2022-12-03T07:24:47.756115Z",
     "shell.execute_reply": "2022-12-03T07:24:47.755344Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.584584Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ResNet50_Weights' from 'torchvision.models' (/home/me.docker/.conda/envs/mmseg/lib/python3.10/site-packages/torchvision/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resnet50, ResNet50_Weights\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ResNet50_Weights' from 'torchvision.models' (/home/me.docker/.conda/envs/mmseg/lib/python3.10/site-packages/torchvision/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "head = LinearHead(in_channels=in_channels, channels=channels,\n",
    "                  in_index=in_index, dropout_ratio=dropout_ratio, num_classes=num_classes, norm_cfg=norm_cfg, \n",
    "                  align_corners=False, loss_decode=loss_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33692af4-e8d7-4702-bb6c-e4125fa9b2b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-03T07:24:47.756672Z",
     "iopub.status.idle": "2022-12-03T07:24:47.756859Z",
     "shell.execute_reply": "2022-12-03T07:24:47.756777Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.756768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet.avgpool = nn.Identity()\n",
    "resnet.fc = nn.Identity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de67dec-4c68-4f4e-9cb1-417601df5d47",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-03T07:24:47.757594Z",
     "iopub.status.idle": "2022-12-03T07:24:47.757917Z",
     "shell.execute_reply": "2022-12-03T07:24:47.757818Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.757807Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06efa9-2d2a-4728-9468-c250c39bed98",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-03T07:24:47.758354Z",
     "iopub.status.idle": "2022-12-03T07:24:47.758527Z",
     "shell.execute_reply": "2022-12-03T07:24:47.758448Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.758439Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751d0b1-286b-418c-85e7-e80d02d06540",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-03T07:24:47.759121Z",
     "iopub.status.idle": "2022-12-03T07:24:47.759316Z",
     "shell.execute_reply": "2022-12-03T07:24:47.759234Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.759226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = resnet(img)\n",
    "res = res.reshape([8,8,8,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce6e3e-af0c-41f0-baf4-83b22d67ce81",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-03T07:24:47.759963Z",
     "iopub.status.idle": "2022-12-03T07:24:47.760133Z",
     "shell.execute_reply": "2022-12-03T07:24:47.760054Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.760046Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "head = head.to(device)\n",
    "res = res.to(device)\n",
    "head(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd15017-9ed6-4414-ad46-018ee7b22593",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-03T07:24:47.760759Z",
     "iopub.status.idle": "2022-12-03T07:24:47.760951Z",
     "shell.execute_reply": "2022-12-03T07:24:47.760872Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.760864Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for img, label in train_loader:\n",
    "    break\n",
    "    \n",
    "for i in range(3):\n",
    "    c_img = img[i].permute(1,2,0)\n",
    "    c_l = label[i].reshape([256,256,1])\n",
    "    for curr_class in np.unique(c_l):\n",
    "        f, axes = plt.subplots(1, 3, figsize=(15,15))\n",
    "        axes[2].imshow(c_img)\n",
    "        axes[1].imshow(c_l == curr_class)\n",
    "        axes[0].imshow(c_img * (c_l == curr_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0f3e8-3ace-471e-b08e-b9dc43029da1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-03T07:24:47.761547Z",
     "iopub.status.idle": "2022-12-03T07:24:47.761716Z",
     "shell.execute_reply": "2022-12-03T07:24:47.761638Z",
     "shell.execute_reply.started": "2022-12-03T07:24:47.761630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "labels_set = set()\n",
    "for _, label in tqdm(train_dst):\n",
    "    labels_set = set(np.unique(label)).union(labels_set)\n",
    "print(labels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4511c7-f0e7-4788-86ae-299a6e2d36e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a6c25-2e83-45f6-8b53-40ddd534cc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec755977-3e9b-4984-b15b-bea05ea83fa2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseg",
   "language": "python",
   "name": "mmseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
